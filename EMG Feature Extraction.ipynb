{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2511b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\anaconda3\\envs\\blurproject\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (5.1.0)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import keras as K\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00498f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(data):\n",
    "    return np.sqrt(np.mean(data ** 2))\n",
    "\n",
    "\n",
    "def hist(data, nbins=20):\n",
    "    histsig, bin_edges = np.histogram(data, bins=nbins)\n",
    "    return tuple(histsig)\n",
    "\n",
    "\n",
    "def entropy(data):\n",
    "    pk = sp.stats.rv_histogram(np.histogram(data, bins=20)).pdf(data)\n",
    "    return sp.stats.entropy(pk)\n",
    "\n",
    "\n",
    "def kurtosis(data):\n",
    "    return sp.stats.kurtosis(data)\n",
    "\n",
    "\n",
    "def zero_cross(data):\n",
    "    return len(np.where(np.diff(np.sign(data)))[0]) / len(data)\n",
    "\n",
    "\n",
    "def min(data):\n",
    "    return np.min(data)\n",
    "\n",
    "\n",
    "def max(data):\n",
    "    return np.max(data)\n",
    "\n",
    "\n",
    "def mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "\n",
    "def median(data):\n",
    "    return np.median(data)\n",
    "\n",
    "\n",
    "def fft(data):\n",
    "    return np.fft.fft(data)\n",
    "\n",
    "\n",
    "def psd(data):\n",
    "    return np.abs(np.fft.fft(data)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c956a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, file):\n",
    "    mat = loadmat(os.path.join(path, file))\n",
    "    data = pd.DataFrame(mat['emg'])\n",
    "    data['stimulus'] = mat['restimulus']\n",
    "    data['repetition'] = mat['repetition']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalise(data, train_reps):\n",
    "    x = [np.where(data.values[:, 13] == rep) for rep in train_reps]\n",
    "    indices = np.squeeze(np.concatenate(x, axis=-1))\n",
    "    train_data = data.iloc[indices, :]\n",
    "    train_data = data.reset_index(drop=True)\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True,\n",
    "                            with_std=True,\n",
    "                            copy=False).fit(train_data.iloc[:, :12])\n",
    "\n",
    "    scaled = scaler.transform(data.iloc[:, :12])\n",
    "    normalised = pd.DataFrame(scaled)\n",
    "    normalised['stimulus'] = data['stimulus']\n",
    "    normalised['repetition'] = data['repetition']\n",
    "    return normalised\n",
    "\n",
    "\n",
    "def filter_data(data, f, butterworth_order=4, btype='lowpass'):\n",
    "    emg_data = data.values[:, :12]\n",
    "\n",
    "    f_sampling = 2000\n",
    "    nyquist = f_sampling / 2\n",
    "    if isinstance(f, int):\n",
    "        fc = f / nyquist\n",
    "    else:\n",
    "        fc = list(f)\n",
    "        for i in range(len(f)):\n",
    "            fc[i] = fc[i] / nyquist\n",
    "\n",
    "    b, a = signal.butter(butterworth_order, fc, btype=btype)\n",
    "    transpose = emg_data.T.copy()\n",
    "\n",
    "    for i in range(len(transpose)):\n",
    "        transpose[i] = (signal.lfilter(b, a, transpose[i]))\n",
    "\n",
    "    filtered = pd.DataFrame(transpose.T)\n",
    "    filtered['stimulus'] = data['stimulus']\n",
    "    filtered['repetition'] = data['repetition']\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def rectify(data):\n",
    "    return abs(data)\n",
    "\n",
    "\n",
    "def windowing(data, reps, gestures, win_len, win_stride):\n",
    "    if reps:\n",
    "        x = [np.where(data.values[:, 13] == rep) for rep in reps]\n",
    "        indices = np.squeeze(np.concatenate(x, axis=-1))\n",
    "        data = data.iloc[indices, :]\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "    if gestures:\n",
    "        x = [np.where(data.values[:, 12] == move) for move in gestures]\n",
    "        indices = np.squeeze(np.concatenate(x, axis=-1))\n",
    "        data = data.iloc[indices, :]\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "    idx = [i for i in range(win_len, len(data), win_stride)]\n",
    "\n",
    "    X = np.zeros([len(idx), win_len, len(data.columns) - 2])\n",
    "    y = np.zeros([len(idx), ])\n",
    "    reps = np.zeros([len(idx), ])\n",
    "\n",
    "    for i, end in enumerate(idx):\n",
    "        start = end - win_len\n",
    "        X[i] = data.iloc[start:end, 0:12].values\n",
    "        y[i] = data.iloc[end, 12]\n",
    "        reps[i] = data.iloc[end, 13]\n",
    "\n",
    "    return X, y, reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea4dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('C:/Users/mukun/Desktop/IITKGP Internship/Data/s1/s1','S1_E1_A1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2893780",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_low = filter_data(data=data, f=20, butterworth_order=4, btype='lowpass')\n",
    "\n",
    "emg_band = filter_data(data=data, f=(20,40), butterworth_order=4, btype='bandpass')\n",
    "\n",
    "emg_high = filter_data(data=data, f=20, butterworth_order=4, btype='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a1ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\anaconda3\\envs\\blurproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rms = rms(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643ec420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             1079.025312\n",
      "1             1280.023437\n",
      "2              221.152821\n",
      "3              176.900175\n",
      "4              414.939491\n",
      "5              446.620767\n",
      "6              330.178231\n",
      "7              641.214156\n",
      "8              436.507929\n",
      "9             1521.847726\n",
      "10             251.920630\n",
      "11             192.258229\n",
      "stimulus         5.692128\n",
      "repetition       3.090025\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4924d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMS:  500.0979326561757\n"
     ]
    }
   ],
   "source": [
    "average_rms = np.mean(rms)\n",
    "print(\"Average RMS: \", average_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b1ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 21,\n",
       " 58,\n",
       " 219,\n",
       " 792,\n",
       " 2858,\n",
       " 11147,\n",
       " 63983,\n",
       " 1737743,\n",
       " 15407866,\n",
       " 102854,\n",
       " 17476,\n",
       " 4459,\n",
       " 1275,\n",
       " 420,\n",
       " 130,\n",
       " 29,\n",
       " 13,\n",
       " 5,\n",
       " 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = hist(data, nbins=20)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983f43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average hist:  (10, 21, 58, 219, 792, 2858, 11147, 63983, 1737743, 15407866, 102854, 17476, 4459, 1275, 420, 130, 29, 13, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "average_hist = np.mean(hist)\n",
    "print(\"Average hist: \", hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e2eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_mean(histogram):\n",
    "    bin_values = np.arange(len(histogram))\n",
    "    total_weight = np.sum(histogram)\n",
    "\n",
    "    mean = np.sum(bin_values * histogram) / total_weight\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c120e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.898741954666152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram_mean(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe0d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.84129557, 13.86535153, 13.99138173, 14.0030338 , 13.95609243,\n",
       "       13.95268138, 13.95926203, 13.90753146, 13.96401531, 13.8123159 ,\n",
       "       13.99525945, 13.98962215, 14.03012423, 14.03012423])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = entropy(data)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b6aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average entropy:  13.949863658360576\n"
     ]
    }
   ],
   "source": [
    "average_entropy = np.mean(entropy)\n",
    "print(\"Average entropy: \", average_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7ecc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.574699 , 25.849886 , 13.950155 , 15.019121 , 13.473644 ,\n",
       "       14.060223 , 15.914549 , 14.253283 , 23.664936 , 18.986076 ,\n",
       "       55.727867 ,  3.4716606, -1.1060382, -1.2600695], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosis = kurtosis(data)\n",
    "kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42dafbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average kurtosis:  16.184286\n"
     ]
    }
   ],
   "source": [
    "average_kurtosis = np.mean(kurtosis)\n",
    "print(\"Average kurtosis: \", average_kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b259019e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3375962071450065"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_cross(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dfb39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\anaconda3\\envs\\blurproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            -12303.000000\n",
       "1            -23873.000000\n",
       "2             -3302.000000\n",
       "3             -3945.000000\n",
       "4             -7189.000000\n",
       "5             -9552.000000\n",
       "6             -8451.000000\n",
       "7             -9467.000000\n",
       "8             -8606.000000\n",
       "9            -25167.000000\n",
       "10            -8414.222656\n",
       "11            -2437.400879\n",
       "stimulus          0.000000\n",
       "repetition        0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = min(data)\n",
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dbbc3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average min:  -8764.759\n"
     ]
    }
   ],
   "source": [
    "average_min = np.mean(min)\n",
    "print(\"Average min: \", average_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ff7a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\anaconda3\\envs\\blurproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             15586.000000\n",
       "1             20316.000000\n",
       "2              3661.761963\n",
       "3              3176.000000\n",
       "4              6295.000000\n",
       "5              6311.000000\n",
       "6              7914.000000\n",
       "7             11528.000000\n",
       "8              8389.000000\n",
       "9             30114.000000\n",
       "10             5896.604492\n",
       "11             2027.485840\n",
       "stimulus         12.000000\n",
       "repetition        6.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = max(data)\n",
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f65af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average max: 8659.489\n"
     ]
    }
   ],
   "source": [
    "average_max = np.mean(max)\n",
    "print(\"Average max:\", average_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19c94523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukun\\anaconda3\\envs\\blurproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            -11.579947\n",
       "1             -5.233460\n",
       "2             -5.976496\n",
       "3             -4.945025\n",
       "4             -2.861733\n",
       "5             -6.374892\n",
       "6             -7.428028\n",
       "7             -8.064356\n",
       "8              7.245286\n",
       "9             -6.349988\n",
       "10            -5.138816\n",
       "11            -9.080110\n",
       "stimulus       3.867075\n",
       "repetition     2.203224\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = mean(data)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43335658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mean:  -4.265518919532055\n"
     ]
    }
   ],
   "source": [
    "average_mean = np.mean(mean)\n",
    "print(\"Average mean: \", average_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f830665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dc8d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  37.89604282  +0.j        , -308.07955796 -77.38963482j,\n",
       "        -169.40842043+130.68313805j, ...,  128.06045478 -15.72235314j,\n",
       "        -169.40842043-130.68313805j, -308.07955796 +77.38963482j],\n",
       "       [-147.33532906  +0.j        ,  -30.6868456  -91.95574143j,\n",
       "         -60.07461409 +33.89180305j, ...,   -4.53563699 +58.93881399j,\n",
       "         -60.07461409 -33.89180305j,  -30.6868456  +91.95574143j],\n",
       "       [ -37.83737779  +0.j        ,   37.26974025 -91.24068332j,\n",
       "        -174.72470341 +19.9349212j , ...,  143.70072798 +21.70501805j,\n",
       "        -174.72470341 -19.9349212j ,   37.26974025 +91.24068332j],\n",
       "       ...,\n",
       "       [ 892.01028347  +0.j        , -568.96734786+269.25110528j,\n",
       "        -260.3229398 -210.58081666j, ..., 1097.77685459 -70.24854381j,\n",
       "        -260.3229398 +210.58081666j, -568.96734786-269.25110528j],\n",
       "       [ 637.79352427  +0.j        , -370.59136851  +9.91177164j,\n",
       "        -224.1322417 -209.20042215j, ...,  759.06765295-157.16569945j,\n",
       "        -224.1322417 +209.20042215j, -370.59136851  -9.91177164j],\n",
       "       [ 395.18000126  +0.j        , -332.31527813+197.36941571j,\n",
       "        -202.63134339 -52.82443229j, ...,  551.4342417 -103.37156598j,\n",
       "        -202.63134339 +52.82443229j, -332.31527813-197.36941571j]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft = fft(data)\n",
    "fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b4d4a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FFT:  (-11.579951687685146-7.000200757829533e-17j)\n"
     ]
    }
   ],
   "source": [
    "average_fft = np.mean(fft)\n",
    "print(\"Average FFT: \", average_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57fae0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1436.1100617 ,  100902.16960962,   45777.29548184, ...,\n",
       "          16646.67246746,   45777.29548184,  100902.16960962],\n",
       "       [  21707.69918798,    9397.54087553,    4757.61357236, ...,\n",
       "           3494.35579708,    4757.61357236,    9397.54087553],\n",
       "       [   1431.66715777,    9713.89583088,   30926.12306589, ...,\n",
       "          21121.0070302 ,   30926.12306589,    9713.89583088],\n",
       "       ...,\n",
       "       [ 795682.3458165 ,  396220.0006236 ,  112112.31332799, ...,\n",
       "        1210048.88039196,  112112.31332799,  396220.0006236 ],\n",
       "       [ 406780.57959474,  137436.20562985,   94000.07839843, ...,\n",
       "         600884.75883849,   94000.07839843,  137436.20562985],\n",
       "       [ 156167.23339494,  149388.13033648,   43849.88197268, ...,\n",
       "         314765.40357645,   43849.88197268,  149388.13033648]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psd = psd(data)\n",
    "psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70779b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSD:  6381804.841468112\n"
     ]
    }
   ],
   "source": [
    "average_psd = np.mean(psd)\n",
    "print(\"Average PSD: \", average_psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb504647",
   "metadata": {},
   "source": [
    "# Spectral domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "190151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_roll_off(data, roll_percent):\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = psd\n",
    "\n",
    "    # Sort the PSD values in descending order\n",
    "    sorted_spectrum = np.sort(power_spectrum)[::-1]\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted PSD values\n",
    "    cumulative_sum = np.cumsum(sorted_spectrum)\n",
    "\n",
    "    # Find the index where the cumulative sum exceeds the roll-off percentage\n",
    "    roll_index = np.argmax(cumulative_sum >= (roll_percent / 100) * np.sum(power_spectrum))\n",
    "\n",
    "    # Calculate the roll-off frequency\n",
    "    sampling_rate = 1  # Modify this if your data has a specific sampling rate\n",
    "    roll_frequency = (roll_index / len(power_spectrum)) * (sampling_rate / 2)\n",
    "\n",
    "    return roll_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4969e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Roll-off Point: 6.350126635592065\n"
     ]
    }
   ],
   "source": [
    "roll_off_point = spectral_roll_off(data, roll_percent=95)\n",
    "print(\"Spectral Roll-off Point:\", roll_off_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb07552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(data):\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = psd\n",
    "\n",
    "    # Calculate the geometric mean of the PSD values\n",
    "    geometric_mean = sp.stats.gmean(power_spectrum)\n",
    "\n",
    "    # Calculate the arithmetic mean of the PSD values\n",
    "    arithmetic_mean = np.mean(power_spectrum)\n",
    "\n",
    "    # Calculate the spectral flatness\n",
    "    flatness = 10 * np.log10(geometric_mean / arithmetic_mean)\n",
    "\n",
    "    return flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be452fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Flatness: [-14.23046312 -11.5150677  -11.21566952 -10.97471299 -10.64486511\n",
      " -11.14622194 -10.23314107 -14.20675717 -10.23314107 -11.14622194\n",
      " -10.64486511 -10.97471299 -11.21566952 -11.5150677 ]\n",
      "Average Spectral Flatness:  -11.421184068074831\n"
     ]
    }
   ],
   "source": [
    "flatness_value = spectral_flatness(data)\n",
    "print(\"Spectral Flatness:\", flatness_value)\n",
    "average_flatness_value = np.mean(flatness_value)\n",
    "print(\"Average Spectral Flatness: \", average_flatness_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9952cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_crust(data, crust_percent):\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = psd\n",
    "\n",
    "    # Sort the PSD values in descending order\n",
    "    sorted_spectrum = np.sort(power_spectrum)[::-1]\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted PSD values\n",
    "    cumulative_sum = np.cumsum(sorted_spectrum)\n",
    "\n",
    "    # Normalize the cumulative sum\n",
    "    cumulative_distribution = cumulative_sum / np.sum(power_spectrum)\n",
    "\n",
    "    # Find the index where the cumulative distribution exceeds the crust percentage\n",
    "    crust_index = np.argmax(cumulative_distribution >= (crust_percent / 100))\n",
    "\n",
    "    # Calculate the crust frequency\n",
    "    sampling_rate = 1  # Modify this if your data has a specific sampling rate\n",
    "    crust_frequency = (crust_index / len(power_spectrum)) * (sampling_rate / 2)\n",
    "\n",
    "    return crust_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9975a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Crust: 5.4001478961709175\n"
     ]
    }
   ],
   "source": [
    "crust_value = spectral_crust(data, crust_percent=85)\n",
    "print(\"Spectral Crust:\", crust_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "460d0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decrease(data):\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = psd\n",
    "\n",
    "    # Take the logarithm (base 10) of the PSD values\n",
    "    log_power_spectrum = np.log10(power_spectrum)\n",
    "\n",
    "    # Calculate the discrete derivative of the logarithmically transformed PSD\n",
    "    derivative = np.diff(log_power_spectrum)\n",
    "\n",
    "    # Calculate the average of the derivative values\n",
    "    average_derivative = np.mean(derivative)\n",
    "\n",
    "    # Calculate the spectral decrease (negative of the average derivative)\n",
    "    spectral_decrease = -average_derivative\n",
    "\n",
    "    return spectral_decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb5b1bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Decrease: -0.020887657109746802\n"
     ]
    }
   ],
   "source": [
    "decrease_value = spectral_decrease(data)\n",
    "print(\"Spectral Decrease:\", decrease_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75bab7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def spectral_slope(data):\n",
    "    # Calculate the Fourier transform of the data\n",
    "    fft_data = np.fft.fft(data)\n",
    "\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = np.abs(fft_data) ** 2\n",
    "\n",
    "    # Get the frequencies corresponding to the PSD values\n",
    "    frequencies = np.fft.fftfreq(len(data))\n",
    "\n",
    "    # Reshape the frequencies array for linear regression\n",
    "    frequencies = frequencies.reshape(-1, 1)\n",
    "\n",
    "    # Fit linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(frequencies, power_spectrum)\n",
    "\n",
    "    # Extract the slope coefficient\n",
    "    slope_coefficient = model.coef_[0]\n",
    "\n",
    "    return slope_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7acd394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Slope: [2523226.53452005]\n"
     ]
    }
   ],
   "source": [
    "slope_value = spectral_slope(data)\n",
    "print(\"Spectral Slope:\", slope_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c8a6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def spectral_spread(data):\n",
    "    # Calculate the power spectral density (PSD)\n",
    "    power_spectrum = np.abs(np.fft.fft(data)) ** 2\n",
    "\n",
    "    # Get the frequencies corresponding to the PSD values\n",
    "    frequencies = np.fft.fftfreq(len(data))\n",
    "\n",
    "    # Reshape the frequencies array for linear regression\n",
    "    frequencies = frequencies.reshape(-1, 1)\n",
    "\n",
    "    # Fit linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(frequencies, power_spectrum)\n",
    "\n",
    "    # Calculate the residuals\n",
    "    residuals = power_spectrum - model.predict(frequencies)\n",
    "\n",
    "    # Calculate the spectral spread\n",
    "    spectral_spread = np.sqrt(np.sum(residuals ** 2 * frequencies) / np.sum(power_spectrum))\n",
    "\n",
    "    return spectral_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fa1c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Spread: 4933.006817993984\n"
     ]
    }
   ],
   "source": [
    "spread_value = spectral_spread(data)\n",
    "print(\"Spectral Spread:\", spread_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f952719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
